{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mbti= pd.read_csv('../gonzaloalvarez/final_project/mbti_changed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>type_index</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>8</td>\n",
       "      <td>enfp  and  intj  moments  sportscenter  not  t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>3</td>\n",
       "      <td>im  finding  the  lack  of  me  in  these  pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>11</td>\n",
       "      <td>good  one    of  course  to  which  i  say  i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>10</td>\n",
       "      <td>dear  intp  i  enjoyed  our  conversation  the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>2</td>\n",
       "      <td>youre  fired  thats  another  silly  misconcep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  type_index  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           8   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...           3   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...          11   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...          10   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...           2   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  enfp  and  intj  moments  sportscenter  not  t...  \n",
       "1  im  finding  the  lack  of  me  in  these  pos...  \n",
       "2  good  one    of  course  to  which  i  say  i ...  \n",
       "3  dear  intp  i  enjoyed  our  conversation  the...  \n",
       "4  youre  fired  thats  another  silly  misconcep...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xids= np.zeros((len(mbti), seq_len))\n",
    "Xmask=np.zeros((len(mbti), seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sequence in enumerate(mbti['cleaned_text']):\n",
    "    tokens=tokenizer.encode_plus(sequence, max_length=seq_len, \n",
    "                                truncation=True, \n",
    "                                padding='max_length')\n",
    "    Xids[i,:], Xmask[i,:]= tokens['input_ids'], tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr= mbti.type_index.values\n",
    "labels=np.zeros((arr.size, arr.max()+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[np.arange(arr.size), arr]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
      "array([  101.,  4372., 22540.,  1998., 20014.,  3501.,  5312.,  2998.,\n",
      "       13013.,  2121.,  2025.,  2327.,  2702.,  3248., 26418.,  2015.,\n",
      "        2054.,  2038.,  2042.,  1996.,  2087.,  2166., 22305.,  2075.,\n",
      "        3325.,  1999.,  2115.,  2166.,  2006.,  9377.,  2005.,  2087.,\n",
      "        1997.,  2651.,  2089.,  1996.,  2566.,  2278.,  3325., 10047.,\n",
      "       16862.,  2063.,  2017.,  1996.,  2197.,  2518.,  2026.,  1999.,\n",
      "        2546.,   102.])>, <tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])>, <tf.Tensor: shape=(16,), dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
      "array([  101.,  4372., 22540.,  1998., 20014.,  3501.,  5312.,  2998.,\n",
      "       13013.,  2121.,  2025.,  2327.,  2702.,  3248., 26418.,  2015.,\n",
      "        2054.,  2038.,  2042.,  1996.,  2087.,  2166., 22305.,  2075.,\n",
      "        3325.,  1999.,  2115.,  2166.,  2006.,  9377.,  2005.,  2087.,\n",
      "        1997.,  2651.,  2089.,  1996.,  2566.,  2278.,  3325., 10047.,\n",
      "       16862.,  2063.,  2017.,  1996.,  2197.,  2518.,  2026.,  1999.,\n",
      "        2546.,   102.])>, 'attention_mask': <tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])>}, <tf.Tensor: shape=(16,), dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= dataset.shuffle(100000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_len= len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "split= 0.9\n",
    "\n",
    "train= dataset.take(round(ds_len*split))\n",
    "val=dataset.skip(round(ds_len*split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert= TFAutoModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f8f80f5a340>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f8f80f5a340>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "input_ids= tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "mask=  tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "\n",
    "embeddings= bert(input_ids, attention_mask= mask)[0]\n",
    "\n",
    "X= tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "X=tf.keras.layers.BatchNormalization()(X)\n",
    "X=tf.keras.layers.Dense(128, activation='relu')(X)\n",
    "X=tf.keras.layers.Dropout(0.1)(X)\n",
    "X=tf.keras.layers.Dense(32, activation='relu')(X)\n",
    "y= tf.keras.layers.Dense(16, activation='softmax', name= 'output')(X)\n",
    "\n",
    "model= tf.keras.Model(inputs=[input_ids, mask], outputs= y)\n",
    "\n",
    "model.layers[2].trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 768)          3072        global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           4128        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 16)           528         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,588,400\n",
      "Trainable params: 104,624\n",
      "Non-trainable params: 109,483,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= tf.keras.optimizers.Adam(0.001)\n",
    "loss= tf.keras.losses.CategoricalCrossentropy()\n",
    "acc= tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss= loss, metrics= [acc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "245/245 [==============================] - ETA: 0s - loss: 2.6612 - accuracy: 0.1460WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "245/245 [==============================] - 445s 2s/step - loss: 2.6605 - accuracy: 0.1462 - val_loss: 2.2376 - val_accuracy: 0.2515\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 459s 2s/step - loss: 2.2319 - accuracy: 0.2449 - val_loss: 2.1072 - val_accuracy: 0.2862\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 489s 2s/step - loss: 2.1914 - accuracy: 0.2606 - val_loss: 2.0433 - val_accuracy: 0.3222\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(train,\n",
    "                  validation_data= val,\n",
    "                  epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 37s 1s/step - loss: 2.0240 - accuracy: 0.3257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0240261554718018, 0.3257485032081604]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack_env]",
   "language": "python",
   "name": "conda-env-ironhack_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
